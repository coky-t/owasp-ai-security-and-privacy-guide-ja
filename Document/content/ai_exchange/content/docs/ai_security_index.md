---
title: 索引
weight: 9
---
> パーマリンク: https://owaspai.org/goto/index/

以下のアルファベット順のクリック可能なトピックを探します。脅威とそのコントロールの概要については [AI セキュリティの周期表](ai_security_overview.md#periodic-table-of-ai-security) をご覧ください。

A  
[敵対的攻撃 (Adversarial attacks)](2_threats_through_use.md#21-evasion)  
[エージェント AI (Agentic AI)](ai_security_overview.md#threats-to-agentic-ai)  
[アライメント (Alignment)](2_threats_through_use.md#model-alignment)  

B  
[バイアス (Bias)](1_general_controls.md#unwantedbiastesting)  

C  
[コンプライアンス (Compliance)](1_general_controls.md#checkcompliance)  
[継続的バリデーション (Continuous validation)](1_general_controls.md#continuousvalidation)  
[貢献 (Contribute)](../contribute.md)  
[コントロール (Controls)](ai_security_overview.md#controls-overview)  
[著作権 (Copyright)](ai_security_overview.md#how-about-copyright)  
[文化的センシティビティ (Cultural sensitivity)](2_threats_through_use.md#appendix-culture-sensitive-alignment)  

D  
[データとモデルのガバナンス (Data and model governance)](3_development_time_threats.md#supplychainmanage)  
[モデル出力でのデータ開示 (Data disclosure in model output)](2_threats_through_use.md#231-sensitive-data-output-from-model)  
[訓練データ/ファインチューンデータのデータポイズニング (Data poisoning of train/finetune data)](3_development_time_threats.md#311-data-poisoning)  
[モデルサービス拒否 (Denial of model service)](2_threats_through_use.md#25-failure-or-malfunction-of-ai-specific-elements-through-use)  
[直接プロンプトインジェクション (Direct prompt injection)](2_threats_through_use.md#222-indirect-prompt-injection)  

E  
[欧州 AI 法 (EU AI Act)](1_general_controls.md#checkcompliance)  
[回避 (Evasion)](2_threats_through_use.md#21-evasion)  
[説明可能性 (Explainability)](1_general_controls.md#explainability)  

F  
[連合学習 (Federated learning)](3_development_time_threats.md#federatedlearning)  

G  
[GDPR](6_privacy.md)  
[生成 AI (Generative AI)](ai_security_overview.md#how-about-generative-ai-eg-llm)  
[ガバナンス (Governance)](1_general_controls.md#11-general-governance-controls)  

I  
[間接プロンプトインジェクション (Indirect prompt injection)](2_threats_through_use/#222-indirect-prompt-injection)  

L  
[LLM (LLMs)](ai_security_overview.md#how-about-generative-ai-eg-llm)  
[ログ記録 (Logging)](2_threats_through_use.md#monitor-use)  

M  
[MCP](ai_security_overview.md#threats-to-agentic-ai)  
[メディア (Media)](../media.md)  
[モデルアライメント (Model alignment)](2_threats_through_use.md#model-alignment)  
[モデル入力の漏洩 (Model input leak)](4_runtime_application_security_threats.md#45-leak-sensitive-input-data)  
[モデル反転 / メンバーシップ推論 (Model inversion / Membership inference)](2_threats_through_use.md#232-model-inversion-and-membership-inference)  
[インジェクションを含むモデル出力 (Model output contains injection)](4_runtime_application_security_threats.md#44-insecure-output-handling)  
[開発環境でのモデルポイズニング (Model poisoning in development-environment)](3_development_time_threats.md#312-development-environment-model-poisoning)  
[実行時のモデルポイズニング (Model poisoning in runtime)](4_runtime_application_security_threats.md#42-runtime-model-poisoning-manipulating-the-model-itself-or-its-inputoutput-logic)  
[訓練データ/ファインチューンデータのデータポイズニングを通じてのモデルポイズニング (Model poisoning through data poisoning of train/finetune data)](3_development_time_threats.md#311-data-poisoning)  
[実行時の直接モデル窃取 (Model theft directly in runtime)](4_runtime_application_security_threats.md#43-direct-runtime-model-theft)  
[サプライチェーンのデータポイズニング (Model poisoning in supply chain)](3_development_time_threats.md#313-supply-chain-model-poisoning)  
[開発時のモデル窃取 (Model theft in development-time)](3_development_time_threats.md#322-model-theft-through-development-time-model-parameter-leak)  
[使用によるモデル窃取 (Model theft through use)](2_threats_through_use.md#24-model-theft-through-use)  
[監視 (Monitoring)](2_threats_through_use.md#monitor-use)  

O  
[監督 (Oversight)](1_general_controls.md/#oversight)  

P  
[周期表 (Periodic table)](ai_security_overview.md#periodic-table-of-ai-security)  
[プライバシー (Privacy)](6_privacy.md)  

R  
[レッドチーミング (Red teaming)](5_testing.md)  
[参考情報 (References)](ai_security_references.md)  
[責任ある AI (Responsible AI)](ai_security_overview.md#how-about-responsible-or-trustworthy-ai)  
[リスク分析 (Risk analysis)](ai_security_overview.md#how-to-select-relevant-threats-and-controls-risk-analysis)  

S  
[安全性トレーニング (Safety training)](2_threats_through_use.md#model-alignment)  
[スポンサー (Sponsoring)](https://owaspai.org/sponsor/)  
[サプライチェーンマネジメント (Supply chain management)](3_development_time_threats.md#supplychainmanage)  

T  
[テスト (Testing)](5_testing.md)  
[脅威モデリング (Threat modelling)](ai_security_overview.md#how-to-select-relevant-threats-and-controls-risk-analysis)  
[脅威 (Threats)](ai_security_overview.md#threats-overview)  
[トレーニングデータの漏洩 (Training data leaks)](3_development_time_threats/#321-development-time-data-leak)  
[透明性 (Transparency)](1_general_controls.md#aitransparency)  
